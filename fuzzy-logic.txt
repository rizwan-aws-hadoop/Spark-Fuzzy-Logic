import spark.implicits._
import org.apache.spark.sql.SparkSession
val spark = SparkSession.builder().appName("Spark SQL basic example").config("spark.some.config.option", "some-value").getOrCreate()
 
val sqlContext = new org.apache.spark.sql.SQLContext(sc)
val G = spark.read.format("csv").option("header", "true").load("./G.csv")
val D = spark.read.format("csv").option("header", "true").load("./D.csv")


val JD = D.join(G, col("CityG") === col("City") && col("CountryG") === col("Country"), "inner")
JD.printSchema

root
 |-- Company: string (nullable = true)
 |-- DUNS: string (nullable = true)
 |-- City: string (nullable = true)
 |-- State: string (nullable = true)
 |-- Country: string (nullable = true)
 |-- Dealogic_Id: string (nullable = true)
 |-- CIK: string (nullable = true)
 |-- CapiqId: string (nullable = true)
 |-- CUSIP: string (nullable = true)
 |-- BusinessDescription: string (nullable = true)
 |-- URL: string (nullable = true)
 |-- PostCode: string (nullable = true)
 |-- NationalityOfBusinessISOCode: string (nullable = true)
 |-- NationalityOfIncorporationISOCode: string (nullable = true)
 |-- NationalityOfIncorporation: string (nullable = true)
 |-- GFS_CLIENT_IDG: string (nullable = true)
 |-- CompanyG: string (nullable = true)
 |-- DUNSG: string (nullable = true)
 |-- CityG: string (nullable = true)
 |-- StateG: string (nullable = true)
 |-- CountryG: string (nullable = true)
 |-- UHC_DUNS_IDG: string (nullable = true)
 |-- UHC_SECTOR_DESCG: string (nullable = true)
 |-- UHC_SUBSECTOR_DESCRIPTIONG: string (nullable = true)

JD.createOrReplaceTempView("JDv")

val G1 = spark.sql("select GFS_CLIENT_IDG, CompanyG, DUNSG, CityG, StateG, CountryG, UHC_DUNS_IDG, UHC_SECTOR_DESCG, UHC_SUBSECTOR_DESCRIPTIONG from JDv")
val D1 = spark.sql("select Company, DUNS, City, State, Country, Dealogic_Id, CIK, CapiqId, CUSIP, BusinessDescription, URL, PostCode,  NationalityOfBusinessISOCode, NationalityOfIncorporationISOCode, NationalityOfIncorporation from JDv")

val Lev = D1.join(G1,levenshtein(D1("Company"), G1("CompanyG")) < 0.1)

Lev.write.format("com.databricks.spark.csv").option("header", "true").save("C:/spark/./Lev.csv")
